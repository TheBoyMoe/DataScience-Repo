{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy and Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover the fundamental concepts of SciPy that will help us create tests to measure our confidence in our statistical results:\n",
    "\n",
    "    - Sample means and population means\n",
    "    - The Central Limit Theorem\n",
    "    - Why we use hypothesis tests\n",
    "    - What errors we can come across and how to classify them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to know the average height of an oak tree in your local park. On Monday, you measure 10 trees and get an average height of 32 ft. On Tuesday, you measure 12 different trees and reach an average height of 35 ft. On Wednesday, you measure the remaining 11 trees in the park, whose average height is 31 ft. Overall, the average height for all trees in your local park is 32.8 ft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual measurements on Monday, Tuesday, and Wednesday are called samples. A sample is a subset of the entire population. The mean of each sample is the sample mean and it is an estimate of the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a population, the mean is a constant value no matter how many times it's recalculated. But with a set of samples, the mean will depend on exactly what samples we happened to choose. From a sample mean, we can then extrapolate the mean of the population as a whole. There are many reasons we might use sampling, such as:\n",
    "\n",
    "    - We don't have data for the whole population.\n",
    "    - We have the whole population data, but it is so large that it is infeasible to analyze.\n",
    "    - We can provide meaningful answers to questions faster with sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Mean: 64.9178578874379\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pop = np.random.normal(loc=65, scale=3.5, size=300)\n",
    "pop_mean = np.mean(pop)\n",
    "\n",
    "print(\"Population Mean: {}\".format(pop_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = np.random.choice(pop, size=30, replace=False)\n",
    "sample_2 = np.random.choice(pop, size=30, replace=False)\n",
    "sample_3 = np.random.choice(pop, size=30, replace=False)\n",
    "sample_4 = np.random.choice(pop, size=30, replace=False)\n",
    "sample_5 = np.random.choice(pop, size=30, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 Mean: 65.023517007708\n"
     ]
    }
   ],
   "source": [
    "sample_1_mean = np.mean(sample_1)\n",
    "print(\"Sample 1 Mean: {}\".format(sample_1_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2 Mean: 65.17276992093296\n"
     ]
    }
   ],
   "source": [
    "sample_2_mean = np.mean(sample_2)\n",
    "print(\"Sample 2 Mean: {}\".format(sample_2_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3 Mean: 65.716104789324\n"
     ]
    }
   ],
   "source": [
    "sample_3_mean = np.mean(sample_3)\n",
    "print(\"Sample 3 Mean: {}\".format(sample_3_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4 Mean: 65.50496903111885\n"
     ]
    }
   ],
   "source": [
    "sample_4_mean = np.mean(sample_4)\n",
    "print(\"Sample 4 Mean: {}\".format(sample_4_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5 Mean: 64.24488107974511\n"
     ]
    }
   ],
   "source": [
    "sample_5_mean = np.mean(sample_5)\n",
    "print(\"Sample 5 Mean: {}\".format(sample_5_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our sample selection is poor we end up with a sample population that is skewed the enitre population. The sample mean will be different from our population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mitigate the risk of having a skewed sample mean â€” take a larger set of samples. The sample mean of a larger sample set will more closely approximate the population mean. This phenomenon, known as the `Central Limit Theorem`, states that if we have a large enough sample size, all of our sample means will be sufficiently close to the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population and find population mean\n",
    "population = np.random.normal(loc=65, scale=100, size=3000)\n",
    "population_mean = np.mean(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select increasingly larger samples\n",
    "extra_small_sample = population[:10]\n",
    "small_sample = population[:50]\n",
    "medium_sample = population[:100]\n",
    "large_sample = population[:500]\n",
    "extra_large_sample = population[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of those samples\n",
    "extra_small_sample_mean = np.mean(extra_small_sample)\n",
    "small_sample_mean = np.mean(small_sample)\n",
    "medium_sample_mean = np.mean(medium_sample)\n",
    "large_sample_mean = np.mean(large_sample)\n",
    "extra_large_sample_mean = np.mean(extra_large_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Small Sample Mean: 56.663163209773245\n",
      "Small Sample Mean: 72.48033183195949\n",
      "Medium Sample Mean: 61.64815116445001\n",
      "Large Sample Mean: 58.20599320978539\n",
      "Extra Large Sample Mean: 61.088390025501965\n",
      "\n",
      "Population Mean: 60.30633786052552\n"
     ]
    }
   ],
   "source": [
    "# Print them all out!\n",
    "print(\"Extra Small Sample Mean: {}\".format(extra_small_sample_mean))\n",
    "print(\"Small Sample Mean: {}\".format(small_sample_mean))\n",
    "print(\"Medium Sample Mean: {}\".format(medium_sample_mean))\n",
    "print(\"Large Sample Mean: {}\".format(large_sample_mean))\n",
    "print(\"Extra Large Sample Mean: {}\".format(extra_large_sample_mean))\n",
    "\n",
    "print(\"\\nPopulation Mean: {}\".format(population_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences seen in result data may be due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to know if men are more likely to sign up for a given programming class than women. We invite 100 men and 100 women to this class. After one week, 34 women sign up, and 39 men sign up. Is the difference real?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken sample means from two different populations, men and women. We want to know if the difference that we observe in these sample means reflects a difference in the population means. To formally answer this question, we need to re-frame it in terms of probability:\n",
    "\n",
    "\"What is the probability that men and women have the same level of interest in this class and that the difference we observed is just chance?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more formal version is: \"What is the probability that the two population means are the same and that the difference we observed in the sample means is just chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These statements are all ways of expressing a `null hypothesis`. A `null hypothesis` is a statement that the observed difference is the result of chance. Hypothesis testing is a mathematical way of determining whether we can be confident that the null hypothesis is false(any correlation is NOT due to chance) - used to determine the validity of the `null hypothesis`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Errors in statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Type I**\n",
    "Or 'false positive' is finding a correlation between two items(any difference is NOT due to chance) where there is none - the `null hypothesis` is rejected, when in fact it is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's say you conduct an A/B test for an online store and conclude that interface B is significantly better than interface A at directing traffic to a checkout page. You have rejected the null hypothesis that there is no difference between the two interfaces, resulting in a 'false positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Type II**\n",
    "Or 'false negative' is faling to find a correlation between items that are actually related - the `null hypothesis` is accepted(i.e. true) when it is in fact false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, with the A/B test situation, let's say that after the test, you concluded that there was no significant difference between interface A and interface B. If there actually is a difference in the population as a whole, your test has resulted in a false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(list1, list2):\n",
    "  return [sample for sample in list1 if sample in list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the true positives and negatives:\n",
    "actual_positive = [2, 5, 6, 7, 8, 10, 18, 21, 24, 25, 29, 30, 32, 33, 38, 39, 42, 44, 45, 47]\n",
    "actual_negative = [1, 3, 4, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 26, 27, 28, 31, 34, 35, 36, 37, 40, 41, 43, 46, 48, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the positives and negatives we determine by running the experiment:\n",
    "experimental_positive = [2, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 32, 35, 36, 38, 39, 40, 45, 46, 49]\n",
    "experimental_negative = [1, 3, 6, 12, 14, 23, 25, 29, 30, 31, 33, 34, 37, 41, 42, 43, 44, 47, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define type_i_errors and type_ii_errors here\n",
    "type_i_errors = intersect(experimental_positive, actual_negative)\n",
    "type_ii_errors = intersect(experimental_negative, actual_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 11, 13, 15, 16, 17, 19, 20, 22, 26, 27, 28, 35, 36, 40, 46, 49]\n",
      "[6, 25, 29, 30, 33, 42, 44, 47]\n"
     ]
    }
   ],
   "source": [
    "print(type_i_errors)\n",
    "print(type_ii_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hypothesis test produces a numerical value - the `p-value`, it is the probability that the `null hypothesis` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `p-value` of 0.05 would mean that there is a 5% chance that the null hypothesis is true - there is a 5% chance that there is no difference between the two population means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before conducting a hypothesis test, we determine the necessary threshold we would need before concluding that the results are significant. A higher p-value is more likely to give a false positive so if we want to be very sure that the result is not due to just chance, we will select a very small p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we want a p-value of less than 0.05, meaning that there is a less than 5% chance that our results are due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the SciPy package to carry out hypothesis testing and discover sorrelations in data. It has a number of built in functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical data:\n",
    "\n",
    "    - One Sample T-Tests\n",
    "    - Two Sample T-Tests\n",
    "    - ANOVA\n",
    "    - Tukey Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical data:\n",
    "\n",
    "    - Binomial Tests\n",
    "    - Chi Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Sample T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Univariate T-test` compares a sample mean to a hypothetical population mean, and answers the question: What is the probability that the sample came from a distribution with the desired mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a `null hypothesis`, which is a prediction that there is no significant difference. The `null hypothesis` that this test examines can be phrased as such: \"The set of samples belongs to a population with the target mean\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy has the `ttest_1samp` which will perform the `1 Sample T-trst`. It returns a `p-value` whixh will tell us wether or not we can reject the `null hypothesis`. Generally a `p-value` of less than 0.05 indicates that the `null hypothesis` is false - the difference is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ttest_1samp` takes two inputs, a distribution of values and an expected mean, and returns the `p-value` and `t-statistic`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "t-statistic, p-value = ttest_1samp(example_distribution, expected_mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "ages = np.array([ 32.,  34.,  29.,  29.,  22.,  39.,  38.,  37.,  38.,  36.,  30.,  26.,  22.,  22.])\n",
    "ages_mean = np.mean(ages)\n",
    "print(ages_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5605155888171379\n"
     ]
    }
   ],
   "source": [
    "expected_mean = 30.0\n",
    "tstat, pval = ttest_1samp(ages, 30)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reject the `null hypothesis`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values give us an idea of how confident we can be in a result. Just because we didt not detect a difference doesnâ€™t mean that there isnâ€™t one. it could be that our sample size was not large enough. Generally, the more samples we have, the smaller a difference weâ€™ll be able to detect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Sample T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way of camparing 2 sets of data, which are both approx. normally distributed. The `null hypothesis`, in this case, is that the 2 distributions have the same mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy provides the `ttest_ind` function to perform a `2 Sample T-Test`. It takes takes the 2 distributions as inputs, and returns the `p-value` and `t-statistic`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "week1 = np.genfromtxt(\"week1.csv\",  delimiter=\",\")\n",
    "week2 = np.genfromtxt(\"week2.csv\",  delimiter=\",\")\n",
    "\n",
    "week1_mean = np.mean(week1)\n",
    "print(week1_mean)\n",
    "\n",
    "week2_mean = np.mean(week2)\n",
    "print(week2_mean)\n",
    "\n",
    "week1_std = np.std(week1)\n",
    "print(week1_std)\n",
    "\n",
    "week2_std = np.std(week2)\n",
    "print(week2_std)\n",
    "\n",
    "tstat, pval = ttest_ind(week1, week2)\n",
    "print(pval)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dangers of multiple T-Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 locations and want to know if the average sales over the last 3 years between the different locations is significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, it seems that we could perform T-tests between each pair of stores.\n",
    "\n",
    "We know that the p-value is the probability that we incorrectly reject the null hypothesis on each t-test. The more t-tests we perform, the more likely that we are to get a false positive, a Type I error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a p-value of 0.05, if the null hypothesis is true then the probability of obtaining a significant result is 1 â€“ 0.05 = 0.95. When we run another t-test, the probability of still getting a correct result is 0.95 * 0.95, or 0.9025. That means our probability of making an error is now close to 10%! This error probability only gets bigger with the more t-tests we do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "a = np.genfromtxt(\"store_a.csv\",  delimiter=\",\")\n",
    "b = np.genfromtxt(\"store_b.csv\",  delimiter=\",\")\n",
    "c = np.genfromtxt(\"store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "a_mean = np.mean(a)\n",
    "b_mean = np.mean(b)\n",
    "c_mean = np.mean(c)\n",
    "\n",
    "print(a_mean)\n",
    "print(b_mean)\n",
    "print(c_mean)\n",
    "\n",
    "a_std = np.std(a)\n",
    "b_std = np.std(b)\n",
    "c_std = np.std(c)\n",
    "\n",
    "print(a_std)\n",
    "print(b_std)\n",
    "print(c_std)\n",
    "\n",
    "a_b_tstat, a_b_pval = ttest_ind(a, b)\n",
    "a_c_tstat, a_c_pval = ttest_ind(a, c)\n",
    "b_c_tstat, b_c_pval = ttest_ind(b, c)\n",
    "\n",
    "print(a_b_pval)\n",
    "print(a_c_pval)\n",
    "print(b_c_pval)\n",
    "\n",
    "# probability of an error\n",
    "error_prob = 1 - (0.95 ** 3)\n",
    "print(error_prob)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing more than 2 numerical data sets, use an `Analysis of Variance` or `ANOVA` test.\n",
    "\n",
    "It tests the null hypothesis that all of the datasets have the same mean. If we reject the null hypothesis with ANOVA, we're saying that at least one of the sets has a different mean; however, it does not tell us which datasets are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy provides the `f_oneway` function to perform `Analysis of Variance` on multiple data sets. It takes each dataset as an input and outputs the `t-statistic` and `p-value`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# compare the video game scores of 3 groups\n",
    "fstat, pval = f_oneway(scores_mathematicians, scores_writers, scores_psychologists)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis, in this case, is that all three populations have the same mean score on this videogame. If we reject this null hypothesis (if we get a p-value less than 0.05), we can say that we are reasonably confident that a pair of datasets is significantly different. After using only ANOVA, we can't make any conclusions on which two populations have a significant difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Hypothesis tests assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running numerical hypothesis tests, the following need to be true:\n",
    "\n",
    "1. samples should be normally distributed(ish), e.g. such tests would not be suitable for traffic data in a city where the data shows a bimodal distribution(morning and evening rush hours)\n",
    "    \n",
    "2. the standard deviations of the different populations should be equal. In ANOVA and 2  Sample T-Tests, using datasets with standard deviations that are significantly different from each other will often obscure the differences in group means. To check for similarity between the standard deviations, it is normally sufficient to divide the two standard deviations and see if the ratio is \"close enough\" to 1. \"Close enough\" may differ in different contexts but generally staying within 10% should suffice.\n",
    "\n",
    "3. the sample must be independent, i.e. the samples in one distribution should not affect the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey's Range Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to identify the specific datasets that are different identified by ANOVA test. The `Tukey's Range Test` can distinguish pairs of distributions from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `statsmodels` package has the `pairwise_tukeyhsd` function for performing `Tukey's Range Test`. We provide the function with a list of the combined distributions and a list of labels which tell the function which elements of the list belong to which dataset. Provide also the significance value, usually 0.05\n",
    "\n",
    "```py\n",
    "movie_scores = np.concatenate([drama_scores, comedy_scores, documentary_scores])\n",
    "labels = ['drama'] * len(drama_scores) + ['comedy'] * len(comedy_scores) + ['documentary'] * len(documentary_scores)\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(movie_scores, labels, 0.05)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will return a table of information, telling you whether or not to reject the null hypothesis for each pair of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```py\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "\n",
    "a = np.genfromtxt(\"store_a.csv\",  delimiter=\",\")\n",
    "b = np.genfromtxt(\"store_b.csv\",  delimiter=\",\")\n",
    "c = np.genfromtxt(\"store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "stat, pval = f_oneway(a, b, c)\n",
    "print pval\n",
    "\n",
    "# Using our data from ANOVA, we create v and l\n",
    "v = np.concatenate([a, b, c])\n",
    "labels = ['a'] * len(a) + ['b'] * len(b) + ['c'] * len(c)\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(v, labels, 0.05)\n",
    "print(tukey_results)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n",
    "=============================================\n",
    "group1 group2 meandiff  lower   upper  reject\n",
    "---------------------------------------------\n",
    "  a      b     7.2767   3.2266 11.3267  True \n",
    "  a      c     4.0115  -0.0385  8.0616 False \n",
    "  b      c    -3.2651  -7.3152  0.7849 False \n",
    "---------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1- and 2-Sample T-Tests, ANOVA, and Tukey's Range test, will not work if we can't find the means of our distributions and compare them. There are occasions when data is divided into two discrete categories, e.g. \"users who made a purchase\" and \"users who did not make a purchase\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where you have a dataset with 2 distinct possiblities, we can use the `Binomial Test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Binomial Test` compares a categorical dataset to some expectation, e.g. percentage of respondents who gave a certain survey respnse to the expected survey response, or the number of heads thrown in a coin toss vs the expected number of heads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis would be that there is no difference between the observed behavior and the expected behavior. If we get a p-value of less than 0.05, we can reject that hypothesis and determine that there is a difference between the observation and expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy includes the `binom_test` to perform `Binomial Tests`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`binom_test` requires three inputs, the number of observed successes, the number of total trials, and an expected probability of success. For example, with 1000 coin flips of a fair coin, we would expect a \"success rate\" (the rate of getting heads), to be 0.5, and the number of trials to be 1000. Let's imagine we get 525 heads. Is the coin weighted? This function call would look like:\n",
    "\n",
    "```py\n",
    "pval = binom_test(525, n=1000, p=0.5)\n",
    "```\n",
    "\n",
    "It returns a p-value, telling us how confident we can be that the sample of values was likely to occur with the specified probability. If we get a p-value less than 0.05, we can reject the null hypothesis and say that it is likely the coin is actually weighted, and that the probability of getting heads is statistically different than 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the goal of VeryAnts's marketing team this quarter was to have 6% of customers click a link that was emailed to them. They sent out a link to 10,000 customers and 510 clicked the link, which comes out to 5.1% instead of 6%. Did they do significantly worse than the target? YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011592032724546606\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "pval = binom_test(510, 10000, 0.06)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next quarter, marketing has tried out a new email tactic, including puns in every line of every email. As a result, 590 people out of 10000 opened the link in the newest email.\n",
    "\n",
    "If we still wanted the mean to be 6% of emails opened, but now have 5.9% of emails opened.\n",
    "Does this new p-value make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6891529835730346\n"
     ]
    }
   ],
   "source": [
    "pval2 = binom_test(590, 10000, 0.06)\n",
    "print(pval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Square Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have more than two categories in our dataset that we want to track we can't use a `Binomial Test`. In these situations use a `Chi Square Test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is useful in situations like:\n",
    "\n",
    "1. An A/B test where half of users were shown a green submit button and the other half were shown a purple submit button. Was one group more likely to click the submit button?\n",
    "\n",
    "2. Men and women were both given a survey asking \"Which of the following three products is your favorite?\" Did the men and women have significantly different preferences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy includes the function `chi2_contingency` to perform the `Chi Square test`.\n",
    "\n",
    "The input is a contingency table where:\n",
    "\n",
    "1. The columns are each a different condition, such as men vs. women or Interface A vs. Interface B\n",
    "\n",
    "2. The rows represent different outcomes, like \"Survey Response A\" vs. \"Survey Response B\" or \"Clicked a Link\" vs. \"Didn't Click\"\n",
    "\n",
    "The table can have as many rows and columns as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the null hypothesis is that there's no significant difference between the datasets. We reject that hypothesis, and state that there is a significant difference between two of the datasets if we get a p-value less than 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The management at the VeryAnts ant store wants to know if their two most popular species of ants, the Leaf Cutter and the Harvester, vary in popularity between 1st, 2nd, and 3rd graders.\n",
    "\n",
    "We have created a table representing the different ants bought by the children in grades 1, 2, and 3 after the last big field trip to VeryAnts. Run the code to see what happens when we enter this table into SciPy's chi-square test.\n",
    "\n",
    "Does the resulting p-value mean that we should reject or accept the null hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15508230807673704\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Contingency table\n",
    "#         harvester |  leaf cutter\n",
    "# ----+------------------+------------\n",
    "# 1st gr | 30       |  10\n",
    "# 2nd gr | 35       |  5\n",
    "# 3rd gr | 28       |  12\n",
    "\n",
    "X = [[30, 10],\n",
    "     [35, 5],\n",
    "     [28, 12]]\n",
    "chi2, pval, dof, expected = chi2_contingency(X)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class of 40 4th graders comes into VeryAnts in the next week and buys 20 sets of Leaf Cutter ants and 20 sets of Harvester ants.\n",
    "\n",
    "Add this data to the contingency table, rerun the chi-square test, and see if there is now a low enough value to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002812834559546625\n"
     ]
    }
   ],
   "source": [
    "X = [[30, 10],\n",
    "     [35, 5],\n",
    "     [28, 12],\n",
    "    [20, 20]]\n",
    "chi2, pval, dof, expected = chi2_contingency(X)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
