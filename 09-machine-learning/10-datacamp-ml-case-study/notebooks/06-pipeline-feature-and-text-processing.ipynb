{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn's Pipeline\n",
    "\n",
    "Sklearn's pipeline allows you to go from raw data to trained mode in a repeatable way in a series of sequential steps. Every step can be encapsulated within the pipeline\n",
    "\n",
    "- the output of one step is the input for the next.\n",
    "- each step is a tuple of two elements, a string `name`, and an object that implements a preprocessing, transform or fit operetion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore deprecation warnings in sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import our custom train_test split function\n",
    "from multilabel import multilabel_train_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "df = pd.read_csv('../data/TrainingData.csv',index_col=0)\n",
    "\n",
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "LABELS = ['Function',\n",
    " 'Use',\n",
    " 'Sharing',\n",
    " 'Reporting',\n",
    " 'Student_Type',\n",
    " 'Position_Type',\n",
    " 'Object_Type',\n",
    " 'Pre_K',\n",
    " 'Operating_Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a pipeline using numeric data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Split and select numeric data only\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[NUMERIC_COLUMNS], \n",
    "    pd.get_dummies(df[LABELS]), \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# fill in any missing values with the imputer\n",
    "# by default it fills in NaNs with the mean of that column\n",
    "steps = [\n",
    "    ('imp', Imputer()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "]\n",
    "\n",
    "# instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit your pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Compute its accuracy\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a pipeline using the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "                         \n",
    "# using one text column\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Position_Extra'],\n",
    "    pd.get_dummies(df[LABELS]),\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "steps = [\n",
    "    ('vec', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a pipeline processing text and numerical data\n",
    "\n",
    "If we wanted to build a model that used ALL available features, both numerical and text, we can't build a simple pipeline with these steps:\n",
    "\n",
    "- the numeric and text preprocessing can not follow each other, each step will not knnow what to do with the other data type.\n",
    "- output of the `CountVectorizer` can't be the input of the `Imputer`.\n",
    "\n",
    "In order to build a pipeline, we need to separetly operate on numeric and text columns, and then combine the results. Sklearn provides two functions, `FunctionTransformer()` and `FeatureUnion()`.\n",
    "\n",
    "**FunctionTransformer**\n",
    "\n",
    "Allows you to define python functions that can be used by the pipeline.\n",
    "\n",
    "- we'll use one to return just the numeric columns\n",
    "- and a second to return just the text columns\n",
    "\n",
    "Using these functions, we can build separate pipelines for text and numeric data.\n",
    "\n",
    "**Feature Union**\n",
    "\n",
    "Combines the return of the numeric and text pipelines, this becomes the input to the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `get_text_data` by using a lambda function and `FunctionTransformer()` to obtain A SINGLE 'text' column, `Position_Extra` in this example.\n",
    "\n",
    "Define the `get_numeric_data` by using a lambda function and `FunctionTransformer()` to obtain all the numeric columns (including missing data), specified by `NUMERIC_COLUMNS`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FeatureTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data\n",
      "134338                 KINDERGARTEN \n",
      "206341                  UNDESIGNATED\n",
      "326408                       TEACHER\n",
      "364634    PROFESSIONAL-INSTRUCTIONAL\n",
      "47683     PROFESSIONAL-INSTRUCTIONAL\n",
      "Name: Position_Extra, dtype: object\n",
      "\n",
      "Numeric Data\n",
      "        FTE      Total\n",
      "134338  1.0  50471.810\n",
      "206341  NaN   3477.860\n",
      "326408  1.0  62237.130\n",
      "364634  NaN     22.300\n",
      "47683   NaN     54.166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['Position_Extra'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FeatureUnion\n",
    "\n",
    "Sklearn's tools allow the streamlining of all preprocessing steps of our model, even when multiple datatypes are involved. For example, we don't want to impute our text data, and we don't want to create a bag-of-words with our numeric data. Instead, we deal with these separately and then join the results together using `FeatureUnion()`.\n",
    "\n",
    "We'll still have two high-level steps in our pipeline: preprocessing and model instantiation. The difference is that the first preprocessing step actually consists of a pipeline for numeric data and a pipeline for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/theboymo/d64061fd-29fa-457c-8209-b6a7ed06885f/home/theboymo/MiniConda/envs/ml37/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/media/theboymo/d64061fd-29fa-457c-8209-b6a7ed06885f/home/theboymo/MiniConda/envs/ml37/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all data:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill NaN values in df.Position_Extra with empty string\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,\n",
    "                                                    pd.get_dummies(df[LABELS]),\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC))\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
