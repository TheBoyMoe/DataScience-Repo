{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore deprecation warnings in sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import our custom train_test split function\n",
    "from multilabel import multilabel_train_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "df = pd.read_csv('../data/TrainingData.csv',index_col=0)\n",
    "\n",
    "# prepare the training and test data\n",
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "LABELS = ['Function',\n",
    " 'Use',\n",
    " 'Sharing',\n",
    " 'Reporting',\n",
    " 'Student_Type',\n",
    " 'Position_Type',\n",
    " 'Object_Type',\n",
    " 'Pre_K',\n",
    " 'Operating_Status']\n",
    "\n",
    "NON_LABELS = [column for column in df.columns if column not in LABELS]\n",
    "\n",
    "labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(\n",
    "    df[NON_LABELS],\n",
    "    labels,\n",
    "    0.2,\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# useful text preprocessing functions\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    \n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, fit and score the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# The parameters non_negative=True, norm=None, and binary=False make the \n",
    "# HashingVectorizer perform similarly to the default settings on the \n",
    "# CountVectorizer so you can just replace one with the other.\n",
    "pl = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('numeric_features', Pipeline([\n",
    "            ('selector', get_numeric_data),\n",
    "            ('imputer', SimpleImputer())\n",
    "        ])),\n",
    "        ('text_features', Pipeline([\n",
    "            ('selector', get_text_data),\n",
    "            ('vectorizer', HashingVectorizer(\n",
    "                norm=None,\n",
    "                binary=False,\n",
    "                non_negative=True,\n",
    "                token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                ngram_range=(1,2)\n",
    "            ))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('int', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    ('clf',  OneVsRestClassifier(LogisticRegression()))\n",
    "])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual result**:\n",
    "\n",
    "Log loss: 1.2258. Performance is about the same as using a `CountVectorizer`, but this is expected since the `HashingVectorizer` should work the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit predictions\n",
    "\n",
    "Export predictions to csv in the appropriate formate for uploading to the DataDriven competition web site.\n",
    "\n",
    "Because all the preprocessing has been built into the pipeline, we don't have to do any preprocessing to the holdout data, `TestData.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = pd.read_csv('../data/TestData.csv', index_col=0)\n",
    "\n",
    "predictions = pl.predict_proba(holdout)\n",
    "columns = pd.get_dummies(df[LABELS], prefix_sep='__').columns\n",
    "\n",
    "# create a dataframe of the predictions\n",
    "df_predictions = pd.DataFrame(\n",
    "    columns=columns,\n",
    "    index=holdout.index,\n",
    "    data=predictions\n",
    ")\n",
    "\n",
    "df_predictions.to_csv('../predictions/predictions.csv')\n",
    "\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
