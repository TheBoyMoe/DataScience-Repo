{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning your model\n",
    "\n",
    "We've evaluated the performance of our k-NN classifier based on its accuracy(the fraction of correctly identified samples). However, accuracy is not always an informative metric, especially when you have a class imbalance, e.g. in a situation where you are detectecing spam emails(are 1% of total) and the vast majority of email is real(99%). Even if you classifier were 99% accurate, which would normally be considered good, it would fail in detecting spam, the purpose of the classifier.  \n",
    "\n",
    "A better way of evaluating the performance of **binary classifiers** is by computing a **confusion matrix** and generating a **classification report**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a binary classification task, e.g. detecting spam email, we can draw up a 2x2 matrix that sumarises performance called a **confusion matrix**.\n",
    "\n",
    "Across the top we have the predicted labels, along the side we have the actual labels.\n",
    "\n",
    "![](../imgs/confusion-matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're trying tp detect spam, spam is the **positive** class.\n",
    "\n",
    "- `true positive` spam emails correctly labelled\n",
    "- `true negative` real emails correctly labelled\n",
    "- `false positive` real emails incorrectly labelled (identified as spam)\n",
    "- `false negative` spam emails incorrectly labelled (identified as real mail)\n",
    "\n",
    "We can compute the **accuracy** of our model using the confusion matrix:\n",
    "\n",
    "- **sum of the diagonal** / **total sum of the matrix**\n",
    "\n",
    "![Confusion matrix](../imgs/confusion-matrix-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several other metrics that can be derived fron the confusion matrix:\n",
    "\n",
    "- **precision**  \n",
    "\n",
    "    - true positives / true positives + false positives  \n",
    "    \n",
    "- **recall / sensitivity / true positive rate**  \n",
    "\n",
    "    - true positives / true positives + false negative  \n",
    "    \n",
    "- **F1 score**  \n",
    "\n",
    "    - 2 * (precision * recall) / (precision + recall)  \n",
    "    \n",
    "**High precision** means that not many real emails are predicted as spam, i.e. low false positive.\n",
    "\n",
    "**High recall** means that most spam emails were predicted correctly.\n",
    "\n",
    "![Confusion matrix](../imgs/confusion-matrix-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement confusion matrix using sklearn\n",
    "\n",
    "The goal is to predict whether or not a given female patient will contract diabetes based on features such as BMI, age, and number of pregnancies. Therefore, it is a **binary classification** problem. A target value of `0` indicates that the patient does not have diabetes, while a value of `1` indicates that the patient does have diabetes.\n",
    "\n",
    "We're to train a **k-NN classifier** to the data and evaluate its performance by generating a confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "pregnancies    768 non-null int64\n",
      "glucose        768 non-null int64\n",
      "diastolic      768 non-null int64\n",
      "triceps        768 non-null int64\n",
      "insulin        768 non-null int64\n",
      "bmi            768 non-null float64\n",
      "dpf            768 non-null float64\n",
      "age            768 non-null int64\n",
      "diabetes       768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "df = pd.read_csv('../data/diabetes.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>84</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.336</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.624</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.268</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "402            5      136         84       41       88  35.0  0.286   35   \n",
       "407            0      101         62        0        0  21.9  0.336   25   \n",
       "418            1       83         68        0        0  18.2  0.624   27   \n",
       "740           11      120         80       37      150  42.3  0.785   48   \n",
       "140            3      128         78        0        0  21.1  0.268   55   \n",
       "\n",
       "     diabetes  \n",
       "402         1  \n",
       "407         0  \n",
       "418         0  \n",
       "740         1  \n",
       "140         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (768, 8)\n",
      "<class 'numpy.ndarray'> (768,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('diabetes', axis=1).values\n",
    "y = df.diabetes.values\n",
    "\n",
    "print(type(X), X.shape)\n",
    "print(type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  30]\n",
      " [ 56  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       206\n",
      "           1       0.61      0.45      0.52       102\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       308\n",
      "   macro avg       0.68      0.65      0.66       308\n",
      "weighted avg       0.71      0.72      0.71       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model and train the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the labels\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support gives the number of samples of the true response that lie in that class on which the classification report was computed. The precision, recall, and f1-score columns, then, gave the respective metrics for that particular class.\n",
    "\n",
    "By analyzing the confusion matrix and classification report, you can get a much better understanding of your classifier's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
