{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing a Perceptron\n",
    "\n",
    "A perceptron is an artificial neuron that can make a simple decision. It has three main components:\n",
    "\n",
    " - **inputs** each input corresponds to a feature, e.g. age, weight, height, etc\n",
    " \n",
    " - **weights** which assigns a certain amount of importance to each input. The larger the weight, the bigger the role the input plays in determining the output \n",
    " \n",
    " - **output** the inputs and weights produce an output. The type of output varies with the nature of the problem, e.g. it could be a binary 1 or 0(Yes or No), or could be any value within a range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Perceptron object at 0x7f80cc675ef0>\n",
      "<class '__main__.Perceptron'>\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    # complete the default constructor method\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "cool_perceptron = Perceptron()    \n",
    "print(cool_perceptron)\n",
    "print(type(cool_perceptron))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating an Output\n",
    "\n",
    "The process of turning the input and weights into an output involves a 2-step process:\n",
    "\n",
    "1. **determining the weighted sum**\n",
    "\n",
    "Determining the weighted sum of the outputs is the sum of the products of each input and corresponding weight, `x` is the input and `w` the weight.\n",
    "\n",
    "![Perceptron](img/perceptron-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement it using the following process:\n",
    "\n",
    "1. Start with a `weighted_sum` of 0.\n",
    "\n",
    "2. Start with the first input and multiply it by its corresponding weight. Add this result to `weighted_sum`.\n",
    "\n",
    "3. Go to the next input and multiply it by its corresponding weight. Add this result to `weighted_sum`.\n",
    "\n",
    "4. Repeat this process for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[2,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    # create variable to store weighted sum\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += inputs[i] * self.weights[i]\n",
    "      \n",
    "    return weighted_sum  \n",
    "cool_perceptron = Perceptron()\n",
    "print(cool_perceptron.weighted_sum([24, 55]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **constrain the weighted sum to produce a desired output**\n",
    "\n",
    "An `activation function` is used to transform the weighted sum into the 'desired' and 'constrained' output, e.g if the input was in the range 100-1000, but the desired out put was a binary 1 or 0 (Yes or No), an `activation function` would be used to transform this.\n",
    "\n",
    "If you want to train a perceptron to detect whether a point is above or below a line, you could use the `sign activation function`. It returns `+1` if the weighted sum is positive, and `-1` if the weighted sum is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "  \n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >= 0:\n",
    "      return 1\n",
    "    else:\n",
    "      return -1\n",
    "    \n",
    "\n",
    "cool_perceptron = Perceptron()\n",
    "print(cool_perceptron.weighted_sum([24, 55]))\n",
    "print(cool_perceptron.activation(55))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Perceptron\n",
    "\n",
    "At the moment our perceptron will be particularly bad at any predictions since we're using random weights. We can train the perceptron by providing it a training set, a collection of random inputs with correctly predicted outputs. Each time we execute a 'training cycle' we change it's weights slightly until we can correctly match all the input-output pairs.\n",
    "\n",
    "Every time the output mismatches the expected label, we say that the perceptron has made a training error — a quantity that measures 'how bad' the perceptron is performing. The goal is to continue training the perceptron until the training error reaches 0.\n",
    "\n",
    "The training error is calculated by subtracting the predicted label value from the actual label value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, since we're using the `Sign activation Function`, the output of the perceptron will be `+1` of `-1`. Since the labels are also `+1` or `-1` there a four possible outcomes:\n",
    "\n",
    "![Perceptron](img/perceptron-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "   \n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >= 0:\n",
    "      return 1\n",
    "    if weighted_sum < 0:\n",
    "      return -1\n",
    "    \n",
    "  def training(self, training_set):\n",
    "    for inputs in training_set:                   \n",
    "      prediction = self.activation(self.weighted_sum(inputs))\n",
    "      actual = training_set[inputs]\n",
    "      error = actual - prediction\n",
    "      \n",
    "cool_perceptron = Perceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking the Weights\n",
    "\n",
    "We tweak the weights of our perceptron, improving it's performance, until the error is 0. We can't change the inputs. The only parameter we can change are the weights.\n",
    "\n",
    "The goal is to find the optimal combination of weights that will produce the correct output for as many points as possible in the dataset.\n",
    "\n",
    "We can’t just play around randomly with the weights until the correct combination magically pops up. There needs to be a way to guarantee that the perceptron improves its performance over time.\n",
    "\n",
    "This is where the Perceptron Algorithm comes in. Although complex, the most important part of the algorithm updates the weight:\n",
    "\n",
    "![Perceptron](img/perceptron-3.png)\n",
    "\n",
    "```py\n",
    "# formula above refactored\n",
    "\n",
    "weight += error * input\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep on tweaking the weights until all possible labels are correctly predicted by the perceptron. This means that multiple passes might need to be made through the `training_set` before the Perceptron Algorithm comes to a halt. If the algorithm doesn't find an error, the perceptron must have correctly predicted the labels for all points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bias Weight\n",
    "\n",
    "There are times when a minor adjustment is needed for the perceptron to be more accurate. We use the bias weight. It takes a default input value of 1 and some random weight value. The updated `weighted_sum` formula:\n",
    "\n",
    "![Perceptron](img/perceptron-4.png)\n",
    "\n",
    "This means updating the code, `num_inputs` becomes 3(instead of 2), and we need to add a bias weight to the list of weights, becomes `[1,1,1]` instead of `[1,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete perceptron code\n",
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "  \n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >= 0:\n",
    "      return 1\n",
    "    if weighted_sum < 0:\n",
    "      return -1\n",
    "    \n",
    "  def training(self, training_set):\n",
    "    foundLine = False\n",
    "    while not foundLine:\n",
    "      total_error = 0\n",
    "      for inputs in training_set:\n",
    "        prediction = self.activation(self.weighted_sum(inputs))\n",
    "        actual = training_set[inputs]\n",
    "        error = actual - prediction\n",
    "        total_error += abs(error)\n",
    "        for i in range(self.num_inputs):\n",
    "          self.weights[i] = self.weights[i] + (error * inputs[i])\n",
    "      if total_error == 0:\n",
    "        foundLine = True\n",
    "      \n",
    "cool_perceptron = Perceptron()\n",
    "small_training_set = {(0,3):1, (3,0):-1, (0,-3):-1, (-3,0):1}\n",
    "\n",
    "cool_perceptron.training(small_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a Linear Classifier\n",
    "\n",
    "A perceptron's weights can be used to find the slope and intercept of the line that the perceptron represents which can be plotted.\n",
    "\n",
    "```py\n",
    "slope = -self.weights[0]/self.weights[1]\n",
    "intercept = -self.weights[2]/self.weights[1]\n",
    "```\n",
    "\n",
    "This allows us to visualize the perceptron, the 1st iteration of the training process and the last.\n",
    "\n",
    "<img src=\"img/perceptron-5.png\" width=\"300\"><img src=\"img/perceptron-6.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the 2nd plot(last iteration) the perceptron found the `linear classifier`, or `decision boundary`, that separates the two distinct set of points in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "There a limits to using a single perceptron. The example we've covered consisted of data points that were `linearly separable`, i.e. a single line could easily separate the two dissimilar sets of points.\n",
    "\n",
    "What would happen if the data points were scattered in such a way that a line could no longer classify the points? A single perceptron with only two inputs wouldn't work for such a scenario because it cannot represent a non-linear decision boundary.\n",
    "\n",
    "That's when more perceptrons and features(inputs) come into play!\n",
    "\n",
    "By increasing the number of features and perceptrons, we can give rise to the Multilayer Perceptrons, also known as Neural Networks, which can solve much more complicated problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
